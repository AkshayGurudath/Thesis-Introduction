
@book{noauthor_notitle_nodate,
}

@misc{noauthor_notitle_nodate-1,
}

@phdthesis{noauthor_notitle_nodate-2,
}

@article{scoring,
    author = "Tilmann Gneitting and Adrian E. Raftery",
    title = "Strictly Proper Scoring Rules, Prediction, and Estimation",
    year = "2007",
    url= "https://viterbi-web.usc.edu/~shaddin/cs699fa17/docs/GR07.pdf"
}
@online{accidents,
    author = "WHO",
    title = "Road Traffic Injuries",
    url  = "https://www.who.int/news-room/fact-sheets/detail/road-traffic-injuries",
}

@online{self_driving,
    author = "Wikipedia",
    title = "Waymo is now allowed to transport passengers in its self driving cars",
    url  = "https://en.wikipedia.org/wiki/Waymo#:~:text=On%20October%2030%2C%202018%2C%20the,roads%20and%20highways%20in%20California.",
}

@article{lstm,
    author = "Sepp Hochreiter",
    title = "Long Short Term Memory",
    year = "1997",
    url= "http://www.bioinf.jku.at/publications/older/2604.pdf"
}
@article{transformer,
    author = "Ashish Vaswani",
    title = "Attention is all you need",
    year = "2017",
    url= "https://arxiv.org/abs/1706.03762"
}

@article{cvmodel,
    author = "Kenshi Saho",
    title = "Kalman Filter for Moving Object Tracking: Performance Analysis and Filter Design",
    year = "2017",
    url= "https://www.intechopen.com/chapters/57673"
}

@article{emalgorithm,
author="R.H. Shumway",
title="An approach to time series smoothing and forecasting using the EM algorithm",
year="1982",
url="https://www.stat.pitt.edu/stoffer/dss_files/em.pdf"
}


@article{razali_pedestrian_2021,
	title = {Pedestrian intention prediction: {A} convolutional bottom-up multi-task approach},
	volume = {130},
	issn = {0968-090X},
	shorttitle = {Pedestrian intention prediction},
	url = {https://www.sciencedirect.com/science/article/pii/S0968090X21002710},
	doi = {10.1016/j.trc.2021.103259},
	abstract = {The ability to predict pedestrian behaviour is crucial for road safety, traffic management systems, Advanced Driver Assistance Systems (ADAS), and more broadly autonomous vehicles. We present a vision-based system that simultaneously locates where pedestrians are in the scene, estimates their body pose and predicts their intention to cross the road. Given a single image, our proposed neural network is designed using a bottom-up approach and thus runs at nearly constant time without relying on a pedestrian detector. Our method jointly detects human body poses and predicts their intention in a multitask framework. Experimental results show that the proposed model outperforms the precision scores of the state-of-the-art for the task of intention prediction by approximately 20\% while running in real-time (5 fps). The source code is publicly available so that it can be easily integrated into an ADAS or into any traffic light management systems.},
	language = {en},
	urldate = {2022-01-20},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {Razali, Haziq and Mordan, Taylor and Alahi, Alexandre},
	month = sep,
	year = {2021},
	keywords = {Advanced Driver Assistance Systems, Autonomous Vehicles, Human Behaviour Analysis, Human Pose Estimation, Pedestrian Intention Prediction, Traffic Management Systems},
	pages = {103259},
	file = {ScienceDirect Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\IBIVW78M\\S0968090X21002710.html:text/html;Full Text:C\:\\Users\\Akshay\\Zotero\\storage\\MS2SXJTQ\\Razali et al. - 2021 - Pedestrian intention prediction A convolutional b.pdf:application/pdf},
}

@inproceedings{saleh_early_2017,
	title = {Early intent prediction of vulnerable road users from visual attributes using multi-task learning network},
	doi = {10.1109/SMC.2017.8123150},
	abstract = {In this paper we are presenting a novel approach for the problem of vulnerable road users (VRUs) attribute prediction which play such critical role for the intent prediction models of VRUs. We formulated the problem as a multi-task learning (MTL) image classification problem and we utilized a convolution neural network (ConvNet) based technique to exploit the commonality between two of the most important attributes of VRUs for intent prediction models (i.e, head orientation and body posture). We achieved classification accuracy scores of 83\% and 76\% for the body posture and head orientation attributes respectively. We compared the performance of our proposed solution against individual single task learning ConvNet models for each attribute and achieved significant overall accuracy over the two attribute classification tasks. Furthermore, we compared our proposed MTL-ConvNet model against other MTL approaches and achieved more than 18\% AP score improvement in the classification of body posture attribute.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Saleh, Khaled and Hossny, Mohammed and Nahavandi, Saeid},
	month = oct,
	year = {2017},
	keywords = {Computer architecture, ConvNet and ADAS, Convolution, deep learning, Head, Intent prediction, Legged locomotion, Predictive models, Roads, VRUs},
	pages = {3367--3372},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\HWZH7BXL\\8123150.html:text/html},
}

@article{mandalia_using_2005,
	title = {Using {Support} {Vector} {Machines} for {Lane}-{Change} {Detection}},
	volume = {49},
	issn = {2169-5067},
	url = {https://doi.org/10.1177/154193120504902217},
	doi = {10.1177/154193120504902217},
	abstract = {Driving is a complex task that requires constant attention, and intelligent transportation systems that support drivers in this task must continually infer driver intentions to produce reasonable, safe responses. In this paper we describe a technique for inferring driver intentions, specifically the intention to change lanes, using support vector machines (SVMs). The technique was applied to experimental data from an instrumented vehicle that included both behavioral data and environmental data. Comparing these results to recent results using a novel ?mind-tracking? technique, we found that SVMs outperformed earlier algorithms and proved especially effective in early detection of driver lane changes.},
	number = {22},
	urldate = {2022-01-22},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Mandalia, Hiren M. and Salvucci, Mandalia Dario D.},
	month = sep,
	year = {2005},
	note = {Publisher: SAGE Publications Inc},
	pages = {1965--1969},
	file = {SAGE PDF Full Text:C\:\\Users\\Akshay\\Zotero\\storage\\5H8RPXCM\\Mandalia and Salvucci - 2005 - Using Support Vector Machines for Lane-Change Dete.pdf:application/pdf},
}

@inproceedings{wiest_probabilistic_2012,
	title = {Probabilistic trajectory prediction with {Gaussian} mixture models},
	doi = {10.1109/IVS.2012.6232277},
	abstract = {In the context of driver assistance, an accurate and reliable prediction of the vehicle's trajectory is beneficial. This can be useful either to increase the flexibility of comfort systems or, in the more interesting case, to detect potentially dangerous situations as early as possible. In this contribution, a novel approach for trajectory prediction is proposed which has the capability to predict the vehicle's trajectory several seconds in advance, the so called long-term prediction. To achieve this, previously observed motion patterns are used to infer a joint probability distribution as motion model. Using this distribution, a trajectory can be predicted by calculating the probability for the future motion, conditioned on the current observed history motion pattern. The advantage of the probabilistic modeling is that the result is not only a prediction, but rather a whole distribution over the future trajectories and a specific prediction can be made by the evaluation of the statistical properties, e.g. the mean of this conditioned distribution. Additionally, an evaluation of the variance can be used to examine the reliability of the prediction.},
	booktitle = {2012 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	author = {Wiest, Jürgen and Höffken, Matthias and Kreßel, Ulrich and Dietmayer, Klaus},
	month = jun,
	year = {2012},
	note = {ISSN: 1931-0587},
	keywords = {Predictive models, Chebyshev approximation, History, Probabilistic logic, Trajectory, Vehicles},
	pages = {141--146},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\Q6QI2M2L\\Wiest et al. - 2012 - Probabilistic trajectory prediction with Gaussian .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\KV3WZXA5\\6232277.html:text/html},
}


@inproceedings{ellis_modelling_2009,
	title = {Modelling pedestrian trajectory patterns with {Gaussian} processes},
	doi = {10.1109/ICCVW.2009.5457470},
	abstract = {We propose a non-parametric model for pedestrian motion based on Gaussian Process regression, in which trajectory data are modelled by regressing relative motion against current position. We show how the underlying model can be learned in an unsupervised fashion, demonstrating this on two databases collected from static surveillance cameras. We furthermore exemplify the use of model for prediction, comparing the recently proposed GP-Bayesfilters with a Monte Carlo method. We illustrate the benefit of this approach for long term motion prediction where parametric models such as Kalman Filters would perform poorly.},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision} {Workshops}, {ICCV} {Workshops}},
	author = {Ellis, David and Sommerlade, Eric and Reid, Ian},
	month = sep,
	year = {2009},
	keywords = {Predictive models, Cameras, Computer vision, Conferences, Gaussian processes, Image motion analysis, Layout, Spline, Surveillance, Uncertainty},
	pages = {1229--1234},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\7W462BG7\\Ellis et al. - 2009 - Modelling pedestrian trajectory patterns with Gaus.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\RDCJIX8A\\5457470.html:text/html},
}

@inproceedings{alahi_social_2016,
	address = {Las Vegas, NV, USA},
	title = {Social {LSTM}: {Human} {Trajectory} {Prediction} in {Crowded} {Spaces}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Social {LSTM}},
	url = {http://ieeexplore.ieee.org/document/7780479/},
	doi = {10.1109/CVPR.2016.110},
	abstract = {Pedestrians follow different trajectories to avoid obstacles and accommodate fellow pedestrians. Any autonomous vehicle navigating such a scene should be able to foresee the future positions of pedestrians and accordingly adjust its path to avoid collisions. This problem of trajectory prediction can be viewed as a sequence generation task, where we are interested in predicting the future trajectory of people based on their past positions. Following the recent success of Recurrent Neural Network (RNN) models for sequence prediction tasks, we propose an LSTM model which can learn general human movement and predict their future trajectories. This is in contrast to traditional approaches which use hand-crafted functions such as Social forces. We demonstrate the performance of our method on several public datasets. Our model outperforms state-of-the-art methods on some of these datasets . We also analyze the trajectories predicted by our model to demonstrate the motion behaviour learned by our model.},
	language = {en},
	urldate = {2022-01-23},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
	month = jun,
	year = {2016},
	pages = {961--971},
	file = {Alahi et al. - 2016 - Social LSTM Human Trajectory Prediction in Crowde.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\6C8W6JED\\Alahi et al. - 2016 - Social LSTM Human Trajectory Prediction in Crowde.pdf:application/pdf},
}

@article{bhattacharyya_long-term_2018,
	title = {Long-{Term} {On}-{Board} {Prediction} of {People} in {Traffic} {Scenes} under {Uncertainty}},
	url = {http://arxiv.org/abs/1711.09026},
	abstract = {Progress towards advanced systems for assisted and autonomous driving is leveraging recent advances in recognition and segmentation methods. Yet, we are still facing challenges in bringing reliable driving to inner cities, as those are composed of highly dynamic scenes observed from a moving platform at considerable speeds. Anticipation becomes a key element in order to react timely and prevent accidents. In this paper we argue that it is necessary to predict at least 1 second and we thus propose a new model that jointly predicts ego motion and people trajectories over such large time horizons. We pay particular attention to modeling the uncertainty of our estimates arising from the non-deterministic nature of natural traffic scenes. Our experimental results show that it is indeed possible to predict people trajectories at the desired time horizons and that our uncertainty estimates are informative of the prediction error. We also show that both sequence modeling of trajectories as well as our novel method of long term odometry prediction are essential for best performance.},
	urldate = {2022-01-23},
	journal = {arXiv:1711.09026 [cs]},
	author = {Bhattacharyya, Apratim and Fritz, Mario and Schiele, Bernt},
	month = jun,
	year = {2018},
	note = {arXiv: 1711.09026},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: CVPR 2018},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\Q7NDXXJS\\Bhattacharyya et al. - 2018 - Long-Term On-Board Prediction of People in Traffic.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\KZ3SXNQX\\1711.html:text/html},
}


@inproceedings{saleh_long-term_2018,
	title = {Long-{Term} {Recurrent} {Predictive} {Model} for {Intent} {Prediction} of {Pedestrians} via {Inverse} {Reinforcement} {Learning}},
	doi = {10.1109/DICTA.2018.8615854},
	abstract = {Recently, the problem of intent and trajectory prediction of pedestrians in urban traffic environments has got some attention from the intelligent transportation research community. One of the main challenges that make this problem even harder is the uncertainty exists in the actions of pedestrians in urban traffic environments, as well as the difficulty in inferring their end goals. In this work, we are proposing a data-driven framework based on Inverse Reinforcement Learning (IRL) and the bidirectional recurrent neural network architecture (B-LSTM) for long-term prediction of pedestrians' trajectories. We evaluated our framework on real-life datasets for agent behavior modeling in traffic environments and it has achieved an overall average displacement error of only 2.93 and 4.12 pixels over 2.0 secs and 3.0 secs ahead prediction horizons respectively. Additionally, we compared our framework against other baseline models based on sequence prediction models only. We have outperformed these models with the lowest margin of average displacement error of more than 5 pixels.},
	booktitle = {2018 {Digital} {Image} {Computing}: {Techniques} and {Applications} ({DICTA})},
	author = {Saleh, Khaled and Hossny, Mohammed and Nahavandi, Saeid},
	month = dec,
	year = {2018},
	keywords = {Predictive models, Trajectory, Uncertainty, Entropy, Planning, Recurrent neural networks, Reinforcement learning},
	pages = {1--8},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\NMET4LSL\\Saleh et al. - 2018 - Long-Term Recurrent Predictive Model for Intent Pr.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\2KDHUS4G\\8615854.html:text/html},
}



@article{bhattacharyya_long-term_2018-1,
	title = {Long-{Term} {On}-{Board} {Prediction} of {People} in {Traffic} {Scenes} under {Uncertainty}},
	url = {http://arxiv.org/abs/1711.09026},
	abstract = {Progress towards advanced systems for assisted and autonomous driving is leveraging recent advances in recognition and segmentation methods. Yet, we are still facing challenges in bringing reliable driving to inner cities, as those are composed of highly dynamic scenes observed from a moving platform at considerable speeds. Anticipation becomes a key element in order to react timely and prevent accidents. In this paper we argue that it is necessary to predict at least 1 second and we thus propose a new model that jointly predicts ego motion and people trajectories over such large time horizons. We pay particular attention to modeling the uncertainty of our estimates arising from the non-deterministic nature of natural traffic scenes. Our experimental results show that it is indeed possible to predict people trajectories at the desired time horizons and that our uncertainty estimates are informative of the prediction error. We also show that both sequence modeling of trajectories as well as our novel method of long term odometry prediction are essential for best performance.},
	urldate = {2022-01-24},
	journal = {arXiv:1711.09026 [cs]},
	author = {Bhattacharyya, Apratim and Fritz, Mario and Schiele, Bernt},
	month = jun,
	year = {2018},
	note = {arXiv: 1711.09026},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: CVPR 2018},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\DP6NW6BX\\Bhattacharyya et al. - 2018 - Long-Term On-Board Prediction of People in Traffic.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\3TPBESB3\\1711.html:text/html},
}

@misc{noauthor_pedestrian_nodate,
	title = {Pedestrian intention prediction: {A} convolutional bottom-up multi-task approach {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Pedestrian intention prediction},
	url = {https://reader.elsevier.com/reader/sd/pii/S0968090X21002710?token=72C09737D74FAD4769E8DB420CB08EEB07A8720C32411DF09B9FF64D637EE764A54CC52FED0E8F28B1F1269CE3833913&originRegion=eu-west-1&originCreation=20220124221319},
	language = {en},
	urldate = {2022-01-24},
	doi = {10.1016/j.trc.2021.103259},
	file = {Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\JPGXEI4B\\S0968090X21002710.html:text/html;Full Text:C\:\\Users\\Akshay\\Zotero\\storage\\YNJA9AL6\\Pedestrian intention prediction A convolutional b.pdf:application/pdf},
}

@book{shumstof2000,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Shumway, Robert H. and Stoffer, David S.},
  biburl = {https://www.bibsonomy.org/bibtex/23f3f370e4b3285502e4836e350c14948/jwbowers},
  citeulike-article-id = {107113},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {005662431181f6d76947019ff55a81fa},
  intrahash = {3f3f370e4b3285502e4836e350c14948},
  keywords = {statistics timeseries},
  publisher = {Springer},
  timestamp = {2009-10-28T04:43:19.000+0100},
  title = {Time Series Analysis and Its Applications},
  year = 2000
}


@article{dempster_maximum_1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} {Via} the \textit{{EM}} {Algorithm}},
	volume = {39},
	issn = {00359246},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1977.tb01600.x},
	doi = {10.1111/j.2517-6161.1977.tb01600.x},
	language = {en},
	number = {1},
	urldate = {2022-04-27},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	month = sep,
	year = {1977},
	pages = {1--22},
	file = {Dempster et al. - 1977 - Maximum Likelihood from Incomplete Data Via the i.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\9FNYYM32\\Dempster et al. - 1977 - Maximum Likelihood from Incomplete Data Via the i.pdf:application/pdf},
}


@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2022-04-28},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\XQPEK82V\\Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\9LUTZGNL\\1706.html:text/html},
}

@article{pascanu_difficulty_2013,
	title = {On the difficulty of training {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1211.5063},
	abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	urldate = {2022-04-28},
	journal = {arXiv:1211.5063 [cs]},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	month = feb,
	year = {2013},
	note = {arXiv: 1211.5063},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Improved description of the exploding gradient problem and description and analysis of the vanishing gradient problem},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\6GNTAY49\\Pascanu et al. - 2013 - On the difficulty of training Recurrent Neural Net.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\9WFYEUCM\\1211.html:text/html},
}

@incollection{miikkulainen_simple_2010,
	address = {Boston, MA},
	title = {Simple {Recurrent} {Network}},
	isbn = {978-0-387-30164-8},
	url = {https://doi.org/10.1007/978-0-387-30164-8_762},
	booktitle = {Encyclopedia of {Machine} {Learning}},
	publisher = {Springer US},
	author = {Miikkulainen, Risto},
	editor = {Sammut, Claude and Webb, Geoffrey I.},
	year = {2010},
	doi = {10.1007/978-0-387-30164-8_762},
	pages = {906--906},
}

@Article{HochSchm97,
  author      = {Sepp Hochreiter and Jürgen Schmidhuber},
  journal     = {Neural Computation},
  title       = {Long Short-Term Memory},
  year        = {1997},
  number      = {8},
  pages       = {1735--1780},
  volume      = {9},
  optabstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  optdoi      = {10.1162/neco.1997.9.8.1735},
  opteprint   = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  opturl      = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}

@article{Robbins&Monro:1951,
  added-at = {2008-10-07T16:03:39.000+0200},
  author = {Robbins, H. and Monro, S.},
  biburl = {https://www.bibsonomy.org/bibtex/2cc1b9aa8927ac4952e93f34094a3eaaf/brefeld},
  interhash = {93d54534a08c30eda9e34d1def03ffa3},
  intrahash = {cc1b9aa8927ac4952e93f34094a3eaaf},
  journal = {Annals of Mathematical Statistics},
  keywords = {imported},
  pages = {400-407},
  timestamp = {2008-10-07T16:03:40.000+0200},
  title = {A stochastic approximation method},
  volume = 22,
  year = 1951
}


@incollection{hutchison_pedestrian_2013,
	address = {Berlin, Heidelberg},
	title = {Pedestrian {Path} {Prediction} with {Recursive} {Bayesian} {Filters}: {A} {Comparative} {Study}},
	volume = {8142},
	shorttitle = {Pedestrian {Path} {Prediction} with {Recursive} {Bayesian} {Filters}},
	url = {http://link.springer.com/10.1007/978-3-642-40602-7_18},
	abstract = {In the context of intelligent vehicles, we perform a comparative study on recursive Bayesian ﬁlters for pedestrian path prediction at short time horizons ({\textless} 2s). We consider Extended Kalman Filters (EKF) based on single dynamical models and Interacting Multiple Models (IMM) combining several such basic models (constant velocity/acceleration/turn). These are applied to four typical pedestrian motion types (crossing, stopping, bending in, starting). Position measurements are provided by an external state-of-the-art stereo vision-based pedestrian detector. We investigate the accuracy of position estimation and path prediction, and the beneﬁt of the IMMs vs. the simpler single dynamical models. Special care is given to the proper sensor modeling and parameter optimization. The dataset and evaluation framework are made public to facilitate benchmarking.},
	language = {en},
	urldate = {2022-04-28},
	booktitle = {Pattern {Recognition}},
	publisher = {Springer Berlin Heidelberg},
	author = {Schneider, Nicolas and Gavrila, Dariu M.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Weickert, Joachim and Hein, Matthias and Schiele, Bernt},
	year = {2013},
	doi = {10.1007/978-3-642-40602-7_18},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {174--183},
	file = {Schneider and Gavrila - 2013 - Pedestrian Path Prediction with Recursive Bayesian.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\BJ5LMX8P\\Schneider and Gavrila - 2013 - Pedestrian Path Prediction with Recursive Bayesian.pdf:application/pdf},
}


@article{he_mask_2018,
	title = {Mask {R}-{CNN}},
	url = {http://arxiv.org/abs/1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
	urldate = {2022-05-04},
	journal = {arXiv:1703.06870 [cs]},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	month = jan,
	year = {2018},
	note = {arXiv: 1703.06870},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: open source; appendix on more results},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\L59NJVAK\\He et al. - 2018 - Mask R-CNN.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\Q9QXDHKE\\1703.html:text/html},
}

@article{fang_rmpe_2018,
	title = {{RMPE}: {Regional} {Multi}-person {Pose} {Estimation}},
	shorttitle = {{RMPE}},
	url = {http://arxiv.org/abs/1612.00137},
	abstract = {Multi-person pose estimation in the wild is challenging. Although state-of-the-art human detectors have demonstrated good performance, small errors in localization and recognition are inevitable. These errors can cause failures for a single-person pose estimator (SPPE), especially for methods that solely depend on human detection results. In this paper, we propose a novel regional multi-person pose estimation (RMPE) framework to facilitate pose estimation in the presence of inaccurate human bounding boxes. Our framework consists of three components: Symmetric Spatial Transformer Network (SSTN), Parametric Pose Non-Maximum-Suppression (NMS), and Pose-Guided Proposals Generator (PGPG). Our method is able to handle inaccurate bounding boxes and redundant detections, allowing it to achieve a 17\% increase in mAP over the state-of-the-art methods on the MPII (multi person) dataset.Our model and source codes are publicly available.},
	urldate = {2022-05-04},
	journal = {arXiv:1612.00137 [cs]},
	author = {Fang, Hao-Shu and Xie, Shuqin and Tai, Yu-Wing and Lu, Cewu},
	month = feb,
	year = {2018},
	note = {arXiv: 1612.00137},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Models \& Codes available at https://github.com/MVIG-SJTU/RMPE or https://github.com/Fang-Haoshu/RMPE},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\I6I4JLZI\\Fang et al. - 2018 - RMPE Regional Multi-person Pose Estimation.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\AGEWL8DG\\1612.html:text/html},
}

@article{bertoni_perceiving_2021,
	title = {Perceiving {Humans}: from {Monocular} {3D} {Localization} to {Social} {Distancing}},
	shorttitle = {Perceiving {Humans}},
	url = {http://arxiv.org/abs/2009.00984},
	abstract = {Perceiving humans in the context of Intelligent Transportation Systems (ITS) often relies on multiple cameras or expensive LiDAR sensors. In this work, we present a new cost-effective vision-based method that perceives humans' locations in 3D and their body orientation from a single image. We address the challenges related to the ill-posed monocular 3D tasks by proposing a neural network architecture that predicts confidence intervals in contrast to point estimates. Our neural network estimates human 3D body locations and their orientation with a measure of uncertainty. Our proposed solution (i) is privacy-safe, (ii) works with any fixed or moving cameras, and (iii) does not rely on ground plane estimation. We demonstrate the performance of our method with respect to three applications: locating humans in 3D, detecting social interactions, and verifying the compliance of recent safety measures due to the COVID-19 outbreak. We show that it is possible to rethink the concept of "social distancing" as a form of social interaction in contrast to a simple location-based rule. We publicly share the source code towards an open science mission.},
	urldate = {2022-05-04},
	journal = {arXiv:2009.00984 [cs]},
	author = {Bertoni, Lorenzo and Kreiss, Sven and Alahi, Alexandre},
	month = mar,
	year = {2021},
	note = {arXiv: 2009.00984},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: IEEE Transactions on Intelligent Transportation Systems},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\4M4N6Y63\\Bertoni et al. - 2021 - Perceiving Humans from Monocular 3D Localization .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\Z8DP8RK6\\2009.html:text/html},
}


@inproceedings{kohler_stereo-vision-based_2015,
	title = {Stereo-{Vision}-{Based} {Pedestrian}'s {Intention} {Detection} in a {Moving} {Vehicle}},
	volume = {2015-October},
	isbn = {978-1-4673-6595-6},
	doi = {10.1109/ITSC.2015.374},
	abstract = {We present a method to detect starting, stopping and bending in intentions of pedestrians from a moving vehicle based on stereo-vision. The method focuses on urban scenarios where these pedestrian movements are common and may result in critical situations. Pedestrian intentions are determined by means of an image-based motion contour histogram of oriented gradient descriptor. It is based on silhouettes gathered from stereo data and does not require any compensation of appearance changes resulting from the ego-motion of a vehicle. Nevertheless, it covers small movements indicating a pedestrian's intention. A linear support vector machine with probabilistic estimates is used for classification. We evaluated our method on the publicly available Daimler Pedestrian Path Prediction Benchmark Dataset containing detections of a stateof-the-art pedestrian detector. We detect a pedestrian's stopping intention from 125 ms to 500 ms before standing still within an accuracy range of 80\% to 100\%. Bending in is detected from 320 ms to 570 ms after a first visible lateral body movement in the same accuracy range. The intention to cross the road from standing still (starting) is detected 250 ms after the first visible motion and, therefore, within the first step with an accuracy of 100\%. © 2015 IEEE.},
	language = {English},
	author = {Kohler, S. and Goldhammer, M. and Zindler, K. and Doll, K. and Dietmeyer, K.},
	year = {2015},
	pages = {2317--2322},
	annote = {Cited By :34},
	file = {Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\RAJCKS3P\\display.html:text/html},
}

@article{keller_will_2014,
	title = {Will the {Pedestrian} {Cross}? {A} {Study} on {Pedestrian} {Path} {Prediction}},
	volume = {15},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Will the {Pedestrian} {Cross}?},
	url = {http://ieeexplore.ieee.org/document/6632960/},
	doi = {10.1109/TITS.2013.2280766},
	abstract = {Future vehicle systems for active pedestrian safety will not only require a high recognition performance but also an accurate analysis of the developing trafﬁc situation. In this paper, we present a study on pedestrian path prediction and action classiﬁcation at short subsecond time intervals. We consider four representative approaches: two novel approaches (based on Gaussian process dynamical models and probabilistic hierarchical trajectory matching) that use augmented features derived from dense optical ﬂow and two approaches as baseline that use positional information only (a Kalman ﬁlter and its extension to interacting multiple models). In experiments using stereo vision data obtained from a vehicle, we investigate the accuracy of path prediction and action classiﬁcation at various time horizons, the effect of various errors (image localization, vehicle egomotion estimation), and the beneﬁt of the proposed approaches. The scenario of interest is that of a crossing pedestrian, who might stop or continue walking at the road curbside. Results indicate similar performance of the four approaches on walking motion, with near-linear dynamics. During stopping, however, the two newly proposed approaches, with nonlinear and/or higher order models and augmented motion features, achieve a more accurate position prediction of 10–50 cm at a time horizon of 0–0.77 s around the stopping event.},
	language = {en},
	number = {2},
	urldate = {2022-05-04},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Keller, Christoph G. and Gavrila, Dariu M.},
	month = apr,
	year = {2014},
	pages = {494--506},
	file = {Keller and Gavrila - 2014 - Will the Pedestrian Cross A Study on Pedestrian P.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\H9T5ICQU\\Keller and Gavrila - 2014 - Will the Pedestrian Cross A Study on Pedestrian P.pdf:application/pdf},
}


@article{liu_spatiotemporal_2020,
	title = {Spatiotemporal {Relationship} {Reasoning} for {Pedestrian} {Intent} {Prediction}},
	volume = {5},
	issn = {2377-3766},
	doi = {10.1109/LRA.2020.2976305},
	abstract = {Reasoning over visual data is a desirable capability for robotics and vision-based applications. Such reasoning enables forecasting the next events or actions in videos. In recent years, various models have been developed based on convolution operations for prediction or forecasting, but they lack the ability to reason over spatiotemporal data and infer the relationships of different objects in the scene. In this letter, we present a framework based on graph convolution to uncover the spatiotemporal relationships in the scene for reasoning about pedestrian intent. A scene graph is built on top of segmented object instances within and across video frames. Pedestrian intent, defined as the future action of crossing or not-crossing the street, is very crucial piece of information for autonomous vehicles to navigate safely and more smoothly. We approach the problem of intent prediction from two different perspectives and anticipate the intention-to-cross within both pedestrian-centric and location-centric scenarios. In addition, we introduce a new dataset designed specifically for autonomous-driving scenarios in areas with dense pedestrian populations: the Stanford-TRI Intent Prediction (STIP) dataset. Our experiments on STIP and another benchmark dataset show that our graph modeling framework is able to predict the intention-to-cross of the pedestrians with an accuracy of 79.10\% on STIP and 79.28\% on Joint Attention for Autonomous Driving (JAAD) dataset up to one second earlier than when the actual crossing happens. These results outperform baseline and previous work. Please refer to http://stip.stanford.edu/ for the dataset and code.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Liu, Bingbin and Adeli, Ehsan and Cao, Zhangjie and Lee, Kuan-Hui and Shenoi, Abhijeet and Gaidon, Adrien and Niebles, Juan Carlos},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Autonomous vehicles, autonomous-driving, Cognition, Convolution, forecasting, graph neural networks, Predictive models, Spatiotemporal graphs, Spatiotemporal phenomena, Videos, Visualization},
	pages = {3485--3492},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\4Z7KVWCI\\Liu et al. - 2020 - Spatiotemporal Relationship Reasoning for Pedestri.pdf:application/pdf},
}


@article{julier_new_1997,
	title = {New extension of the {Kalman} filter to nonlinear systems},
	url = {https://www.semanticscholar.org/paper/New-extension-of-the-Kalman-filter-to-nonlinear-Julier-Uhlmann/a8b141556f2dd7694e5f6343f8ce3650f8ca5b60},
	abstract = {It is argued that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications. The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.},
	language = {en},
	urldate = {2022-05-05},
	journal = {undefined},
	author = {Julier, S. and Uhlmann, J.},
	year = {1997},
	file = {Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\372AX552\\a8b141556f2dd7694e5f6343f8ce3650f8ca5b60.html:text/html},
}

@misc{noauthor_unscented_nodate,
	title = {The unscented {Kalman} filter for nonlinear estimation {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/882463},
	urldate = {2022-05-05},
	file = {The unscented Kalman filter for nonlinear estimation | IEEE Conference Publication | IEEE Xplore:C\:\\Users\\Akshay\\Zotero\\storage\\8SFWRXIN\\882463.html:text/html},
}


@article{wu_interacting_2020,
	title = {Interacting {Multiple} {Model}-{Based} {Adaptive} {Trajectory} {Prediction} for {Anticipative} {Human} {Following} of {Mobile} {Industrial} {Robot}},
	volume = {176},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050920322456},
	doi = {10.1016/j.procs.2020.09.330},
	abstract = {Abstract In smart manufacturing, the introduction of mobile industrial robot has facilitated efficient and flexible production. Mobile iIndsumstariratl mroabnoutfahcatsutrhinegc,atphaebiilnityroodfufcotilolonwoinf gmhoubmilaeniondpuersatrtioarls rtobcootohrdaisnaftaeciwlitiathtetdheemffitcoiecnotmapnldeteflecxoimblpelicpartoedducotpioerna.tiMonosb. iIlne tihnidsucsotrniatelxrto,bfoltlohwasinthgetacragpeatbpielirtsyonofrofoblulostwlyinisgahsuimgnainficoapnetraptroerrseqtouicsoitoerfdoirnamteobwiliethrothbeomt otfofecrionmgpalsestiestcaonmcep.lHicoawteedvoepr,etrhaetiomnosb. iIlne rthoibsoctownittehxlti,mfoiltleodwfinelgdtoarfgveitewpemrsoayn lrosbeutshtleydiysnaasmigincitfaicrgaent dpurerirnegqufoisliltoewfoinrgm, wobhiilcehroebasoitlyoflfeeardinsgtoafsosilslotawnicneg. Hfaoilwureev.eIrn, theismpoabpielre, trhoebroetfworieth, alnimaintetidcifpiealtdivoefhvuiemwanmfaoyllloowseinthgeadpypnroaamcihc itsaragdeotpdtuerdi.nTghfoisllmowetihnogd, wishaicphpreoapsriliyatleeafodrs otomfnoildloirwecintigonfaaillumreo.bIinlethinisdupsatpriearl, rthoebroetfoeqreu,ipanpeadnwticitihpaativviesuhaulmseansfoorllwoiwthinlgimaiptepdropaecrhceipstaiodnopratendg.eT. hWisempreothpodseisa anpopvreolpIrniateterafcotirnogmMnuidltiirpelcetiMonoadl eml-obbaisledinaduaspttriivael trroabjeoctteoqruyipppreeddiwctiitohna avligsuoarilthsemn.soTrhweithalgliomrithedmpeinrctegprtiaotensratnwgoe. pWhyespicros-pboasseead nmovoetiloInntemraocdteinlsg ManudltiapdleapMtivoedleyl-baadsjuedstsadmapotdiveel ptraarjaemcteotreyrspfroerdicntciorenasainlggoarictchumra. cTyhoef palrgeodricitthiomn. iBntaesgerdatoens tthweoprpehdyicstiicosn-b, amseodbilme orotiboont mploandselistsapnadthaadnadptcivoenlfyiguadrajutisotns dmuoridnegl fpoalrlaomweintegrsinfoardvinacnrceeastoinagvoacidcuorbasctyacolefsparnediacctihoine.vBe arosebdusotnfotlhloewpirnegd.icCtioomn,pamriosboinlererosublotst pdleamnosnitsstrpataeththaantdthceopnrfoigpuorsaetdioanppdruorainchg cfoalnlopwreindgicitnhaudmvaannctreatjoecatvooryidmoobrsetaacclceusraantedlya,chaniedvererdoubcuesthfeoldloewviiantgio.nCboemtwpaereinsotnherehsuumltsandeamndonthsetracteentheratotfhveipewropoofstehde aropbporot.ach can predict human trajectory more accurately, and reduce the deviation between the human and the center of view of the robot.},
	language = {en},
	urldate = {2022-05-04},
	journal = {Procedia Computer Science},
	author = {Wu, Hao and Xu, Wenjun and Yao, Bitao and Hu, Yang and Feng, Hao},
	year = {2020},
	pages = {3692--3701},
	file = {Wu et al. - 2020 - Interacting Multiple Model-Based Adaptive Trajecto.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\NI87T6DY\\Wu et al. - 2020 - Interacting Multiple Model-Based Adaptive Trajecto.pdf:application/pdf},
}


@article{mazor_interacting_1998,
	title = {Interacting multiple model methods in target tracking: a survey},
	volume = {34},
	issn = {1557-9603},
	shorttitle = {Interacting multiple model methods in target tracking},
	doi = {10.1109/7.640267},
	abstract = {The Interacting Multiple Model (IMM) estimator is a suboptimal hybrid filter that has been shown to be one of the most cost-effective hybrid state estimation schemes. The main feature of this algorithm is its ability to estimate the state of a dynamic system with several behavior modes which can "switch" from one to another. In particular, the IMM estimator can be a self-adjusting variable-bandwidth filter, which makes it natural for tracking maneuvering targets. The importance of this approach is that it is the best compromise available currently-between complexity and performance: its computational requirements are nearly linear in the size of the problem (number of models) while its performance is almost the same as that of an algorithm with quadratic complexity. The objective of this work is to survey and put in perspective the existing IMM methods for target tracking problems. Special attention is given to the assumptions underlying each algorithm and its applicability to various situations.},
	number = {1},
	journal = {IEEE Transactions on Aerospace and Electronic Systems},
	author = {Mazor, E. and Averbuch, A. and Bar-Shalom, Y. and Dayan, J.},
	month = jan,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Aerospace and Electronic Systems},
	keywords = {Collision avoidance, Control systems, Filters, Marine vehicles, Missiles, State estimation, Surveillance, Target tracking, Trajectory, Weapons},
	pages = {103--123},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\LRSV3QLM\\640267.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\9ES5WCXS\\Mazor et al. - 1998 - Interacting multiple model methods in target track.pdf:application/pdf},
}




@inproceedings{hoermann_probabilistic_2017,
	address = {Los Angeles, CA, USA},
	title = {Probabilistic long-term prediction for autonomous vehicles},
	isbn = {978-1-5090-4804-5},
	url = {http://ieeexplore.ieee.org/document/7995726/},
	doi = {10.1109/IVS.2017.7995726},
	abstract = {Long-term prediction of trafﬁc participants is crucial to enable autonomous driving on public roads. The quality of the prediction directly affects the frequency of trajectory planning. With a poor estimation of the future development, more computational effort has to be put in re-planning, and a safe vehicle state at the end of the planning horizon is not guaranteed. A holistic probabilistic prediction, considering inputs, results and parameters as random variables, highly reduces the problem. A time frame of several seconds requires a probabilistic description of the scene evolution, where uncertainty or accuracy is represented by the trajectory distribution. Following this strategy, a novel evaluation method is needed, coping with the fact, that the future evolution of a scene is also uncertain. We present a method to evaluate the probabilistic prediction of real trafﬁc scenes with varying start conditions. The proposed prediction is based on a particle ﬁlter, estimating behavior describing parameters of a microscopic trafﬁc model. Experiments on real trafﬁc data with random leading vehicles show the applicability in terms of convergence, enabling long-term prediction using forward propagation.},
	language = {en},
	urldate = {2022-01-22},
	booktitle = {2017 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	publisher = {IEEE},
	author = {Hoermann, Stefan and Stumper, Daniel and Dietmayer, Klaus},
	month = jun,
	year = {2017},
	pages = {237--243},
	file = {Hoermann et al. - 2017 - Probabilistic long-term prediction for autonomous .pdf:C\:\\Users\\Akshay\\Zotero\\storage\\FVX9FRFS\\Hoermann et al. - 2017 - Probabilistic long-term prediction for autonomous .pdf:application/pdf},
}



@article{liu_probabilistic_2022,
	title = {A probabilistic architecture of long-term vehicle trajectory prediction for autonomous driving},
	issn = {2095-8099},
	url = {https://www.sciencedirect.com/science/article/pii/S2095809922001412},
	doi = {10.1016/j.eng.2021.12.020},
	abstract = {In mixed and dynamic traffic environments, accurate long-term trajectory forecasting of surrounding vehicles is one of the indispensable preconditions for autonomous vehicles (AVs) to accomplish reasonable behavioral decisions and guarantee driving safety. In this paper, we propose an integrated probabilistic architecture for long-term vehicle trajectory prediction, which consists of a driving inference model (DIM) and a trajectory prediction model (TPM). The DIM is designed and employed to accurately infer the potential driving intention based on a dynamic Bayesian network. The proposed DIM incorporates the basic traffic rules and multivariate vehicle motion information. To further improve the prediction accuracy and realize uncertainty estimation, we develop a Gaussian process (GP)-based TPM, considering both the short-term prediction results of the vehicle model and the driving motion characteristics. Afterward, the effectiveness of our novel approach is demonstrated by conducting experiments on a public naturalistic driving dataset under lane-changing scenarios. The superior performance on the task of long-term trajectory prediction is presented and verified by comparing with other advanced methods.},
	language = {en},
	urldate = {2022-05-04},
	journal = {Engineering},
	author = {Liu, Jinxin and Luo, Yugong and Zhong, Zhihua and Li, Keqiang and Huang, Heye and Xiong, Hui},
	month = mar,
	year = {2022},
	keywords = {Autonomous driving, Driving intention recognition, Dynamic Bayesian network, Gaussian process, Vehicle trajectory prediction},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\D5RLET8X\\Liu et al. - 2022 - A probabilistic architecture of long-term vehicle .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\ZG9V6WHC\\S2095809922001412.html:text/html},
}

@inproceedings{karasev_intent-aware_2016,
	address = {Stockholm, Sweden},
	title = {Intent-aware long-term prediction of pedestrian motion},
	isbn = {978-1-4673-8026-3},
	url = {http://ieeexplore.ieee.org/document/7487409/},
	doi = {10.1109/ICRA.2016.7487409},
	abstract = {We present a method to predict long-term motion of pedestrians, modeling their behavior as jump-Markov processes with their goal a hidden variable. Assuming approximately rational behavior, and incorporating environmental constraints and biases, including time-varying ones imposed by trafﬁc lights, we model intent as a policy in a Markov decision process framework. We infer pedestrian state using a Rao-Blackwellized ﬁlter, and intent by planning according to a stochastic policy, reﬂecting individual preferences in aiming at the same goal.},
	language = {en},
	urldate = {2022-05-04},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Karasev, Vasiliy and Ayvaci, Alper and Heisele, Bernd and Soatto, Stefano},
	month = may,
	year = {2016},
	pages = {2543--2549},
	file = {Karasev et al. - 2016 - Intent-aware long-term prediction of pedestrian mo.pdf:C\:\\Users\\Akshay\\Zotero\\storage\\6KTNTNEE\\Karasev et al. - 2016 - Intent-aware long-term prediction of pedestrian mo.pdf:application/pdf},
}



@inproceedings{saleh_intent_2017,
	title = {Intent prediction of vulnerable road users from motion trajectories using stacked {LSTM} network},
	doi = {10.1109/ITSC.2017.8317941},
	abstract = {Intent prediction of vulnerable road users (VRUs) has got some attention recently from the research community, due to its critical role in the advancement of both advanced driving assistance systems (ADAS) and highly automated vehicles development. Most of the proposed techniques for addressing the intent prediction problem have been focusing mainly on two methodologies, namely dynamical motion modelling and motion planning. Despite how powerful these techniques are, but they both rely on hand crafting a set of specific features which are scene specific, which in return affects their generalization to unseen scenes which involves VRUs. In this paper a novel end-to-end data-driven approach is proposed for long-term intent prediction of VRUs such as pedestrians in urban traffic environment based solely on their motion trajectories. The intent prediction problem was formulated as a time-series prediction problem, whereas by just observing a short-window sequence of motion trajectory of pedestrians, a forecasting about their future lateral positions can be made up to 4 secs ahead. In the proposed approach, we utilized the widely adopted architecture of recurrent neural networks, Long-Short Term Memory networks (LSTM) architecture to form a deep stacked LSTM network. The proposed stacked LSTM model was evaluated on one of the popular datasets for intent and path prediction of pedestrians in four unique traffic scenarios that involve pedestrians in an urban environment. Our proposed approach demonstrated competent results in comparison to the baseline approaches in terms of long-term prediction with small lateral position error of 0.39 meters, 0.48 meters, 0.46 meters and 0.51 meters respectively in the four scenarios of the testing dataset.},
	booktitle = {2017 {IEEE} 20th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	author = {Saleh, Khaled and Hossny, Mohammed and Nahavandi, Saeid},
	month = oct,
	year = {2017},
	note = {ISSN: 2153-0017},
	keywords = {Dynamics, Logic gates, Predictive models, Recurrent neural networks, Task analysis, Trajectory, Vehicle dynamics},
	pages = {327--332},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\Z5K5DMY2\\8317941.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\QGL8W2V2\\Saleh et al. - 2017 - Intent prediction of vulnerable road users from mo.pdf:application/pdf},
}

@article{xin_intention-aware_2019,
	title = {Intention-aware {Long} {Horizon} {Trajectory} {Prediction} of {Surrounding} {Vehicles} using {Dual} {LSTM} {Networks}},
	url = {http://arxiv.org/abs/1906.02815},
	abstract = {As autonomous vehicles (AVs) need to interact with other road users, it is of importance to comprehensively understand the dynamic traffic environment, especially the future possible trajectories of surrounding vehicles. This paper presents an algorithm for long-horizon trajectory prediction of surrounding vehicles using a dual long short term memory (LSTM) network, which is capable of effectively improving prediction accuracy in strongly interactive driving environments. In contrast to traditional approaches which require trajectory matching and manual feature selection, this method can automatically learn high-level spatial-temporal features of driver behaviors from naturalistic driving data through sequence learning. By employing two blocks of LSTMs, the proposed method feeds the sequential trajectory to the first LSTM for driver intention recognition as an intermediate indicator, which is immediately followed by a second LSTM for future trajectory prediction. Test results from real-world highway driving data show that the proposed method can, in comparison to state-of-art methods, output more accurate and reasonable estimate of different future trajectories over 5s time horizon with root mean square error (RMSE) for longitudinal and lateral prediction less than 5.77m and 0.49m, respectively.},
	urldate = {2022-05-05},
	journal = {arXiv:1906.02815 [cs, stat]},
	author = {Xin, Long and Wang, Pin and Chan, Ching-Yao and Chen, Jianyu and Li, Shengbo Eben and Cheng, Bo},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02815},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	annote = {Comment: Published at the 21st International Conference on Intelligent Transportation Systems (ITSC), 2018},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\23DDLRFL\\Xin et al. - 2019 - Intention-aware Long Horizon Trajectory Prediction.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\M4SPPPIS\\1906.html:text/html},
}

@article{dai_modeling_2019,
	title = {Modeling {Vehicle} {Interactions} via {Modified} {LSTM} {Models} for {Trajectory} {Prediction}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2907000},
	abstract = {The long short-term memory (LSTM) model is one of the most commonly used vehicle trajectory predicting models. In this paper, we study two problems of the existing LSTM models for long-term trajectory prediction in dense traffic. First, the existing LSTM models cannot simultaneously describe the spatial interactions between different vehicles and the temporal relations between the trajectory time series. Thus, the existing models cannot accurately estimate the influence of the interactions in dense traffic. Second, the basic LSTM models often suffer from vanishing gradient problem and are, thus, hard to train for long time series. These two problems sometimes lead to large prediction errors in vehicle trajectory predicting. In this paper, we proposed a spatio-temporal LSTM-based trajectory prediction model (ST-LSTM) which includes two modifications. We embed spatial interactions into LSTM models to implicitly measure the interactions between neighboring vehicles. We also introduce shortcut connections between the inputs and the outputs of two consecutive LSTM layers to handle gradient vanishment. The proposed new model is evaluated on the I-80 and US-101 datasets. Results show that our new model has a higher trajectory predicting accuracy than one state-of-the-art model [maneuver-LSTM (M-LSTM)].},
	journal = {IEEE Access},
	author = {Dai, Shengzhe and Li, Li and Li, Zhiheng},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Brakes, Hidden Markov models, long short-term memory (LSTM), Predictive models, Roads, shortcut connection, Time series analysis, Training, Trajectory, Trajectory prediction, vehicle interactions},
	pages = {38287--38296},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Akshay\\Zotero\\storage\\6H9SRD6N\\8672889.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\3U4CANEJ\\Dai et al. - 2019 - Modeling Vehicle Interactions via Modified LSTM Mo.pdf:application/pdf},
}







@article{sighencea_review_2021,
	title = {A {Review} of {Deep} {Learning}-{Based} {Methods} for {Pedestrian} {Trajectory} {Prediction}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/22/7543},
	doi = {10.3390/s21227543},
	abstract = {Pedestrian trajectory prediction is one of the main concerns of computer vision problems in the automotive industry, especially in the field of advanced driver assistance systems. The ability to anticipate the next movements of pedestrians on the street is a key task in many areas, e.g., self-driving auto vehicles, mobile robots or advanced surveillance systems, and they still represent a technological challenge. The performance of state-of-the-art pedestrian trajectory prediction methods currently benefits from the advancements in sensors and associated signal processing technologies. The current paper reviews the most recent deep learning-based solutions for the problem of pedestrian trajectory prediction along with employed sensors and afferent processing methodologies, and it performs an overview of the available datasets, performance metrics used in the evaluation process, and practical applications. Finally, the current work exposes the research gaps from the literature and outlines potential new research directions.},
	language = {en},
	number = {22},
	urldate = {2022-05-05},
	journal = {Sensors},
	author = {Sighencea, Bogdan Ilie and Stanciu, Rareș Ion and Căleanu, Cătălin Daniel},
	month = jan,
	year = {2021},
	note = {Number: 22
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {autonomous vehicles, deep learning, pedestrian behavior, sensor technologies, trajectory prediction},
	pages = {7543},
	file = {Full Text PDF:C\:\\Users\\Akshay\\Zotero\\storage\\IEEX9NIK\\Sighencea et al. - 2021 - A Review of Deep Learning-Based Methods for Pedest.pdf:application/pdf},
}



@article{bahdanau_neural_2016,
	title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
	url = {http://arxiv.org/abs/1409.0473},
	abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
	urldate = {2022-05-05},
	journal = {arXiv:1409.0473 [cs, stat]},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	month = may,
	year = {2016},
	note = {arXiv: 1409.0473},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: Accepted at ICLR 2015 as oral presentation},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\5RQC7SIT\\Bahdanau et al. - 2016 - Neural Machine Translation by Jointly Learning to .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\EINCUPJW\\1409.html:text/html},
}

@article{sharma_action_2016,
	title = {Action {Recognition} using {Visual} {Attention}},
	url = {http://arxiv.org/abs/1511.04119},
	abstract = {We propose a soft attention based model for the task of action recognition in videos. We use multi-layered Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units which are deep both spatially and temporally. Our model learns to focus selectively on parts of the video frames and classifies videos after taking a few glimpses. The model essentially learns which parts in the frames are relevant for the task at hand and attaches higher importance to them. We evaluate the model on UCF-11 (YouTube Action), HMDB-51 and Hollywood2 datasets and analyze how the model focuses its attention depending on the scene and the action being performed.},
	urldate = {2022-05-05},
	journal = {arXiv:1511.04119 [cs]},
	author = {Sharma, Shikhar and Kiros, Ryan and Salakhutdinov, Ruslan},
	month = feb,
	year = {2016},
	note = {arXiv: 1511.04119},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\44WZB6J7\\Sharma et al. - 2016 - Action Recognition using Visual Attention.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\X8EYKXHP\\1511.html:text/html},
}


@article{xu_show_2016,
	title = {Show, {Attend} and {Tell}: {Neural} {Image} {Caption} {Generation} with {Visual} {Attention}},
	shorttitle = {Show, {Attend} and {Tell}},
	url = {http://arxiv.org/abs/1502.03044},
	abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
	urldate = {2022-05-05},
	journal = {arXiv:1502.03044 [cs]},
	author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
	month = apr,
	year = {2016},
	note = {arXiv: 1502.03044},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\AVJQZUE2\\Xu et al. - 2016 - Show, Attend and Tell Neural Image Caption Genera.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\IF2B2F89\\1502.html:text/html},
}


@article{fernando_soft_2017-2,
	title = {Soft + {Hardwired} {Attention}: {An} {LSTM} {Framework} for {Human} {Trajectory} {Prediction} and {Abnormal} {Event} {Detection}},
	shorttitle = {Soft + {Hardwired} {Attention}},
	url = {http://arxiv.org/abs/1702.05552},
	abstract = {As humans we possess an intuitive ability for navigation which we master through years of practice; however existing approaches to model this trait for diverse tasks including monitoring pedestrian flow and detecting abnormal events have been limited by using a variety of hand-crafted features. Recent research in the area of deep-learning has demonstrated the power of learning features directly from the data; and related research in recurrent neural networks has shown exemplary results in sequence-to-sequence problems such as neural machine translation and neural image caption generation. Motivated by these approaches, we propose a novel method to predict the future motion of a pedestrian given a short history of their, and their neighbours, past behaviour. The novelty of the proposed method is the combined attention model which utilises both "soft attention" as well as "hard-wired" attention in order to map the trajectory information from the local neighbourhood to the future positions of the pedestrian of interest. We illustrate how a simple approximation of attention weights (i.e hard-wired) can be merged together with soft attention weights in order to make our model applicable for challenging real world scenarios with hundreds of neighbours. The navigational capability of the proposed method is tested on two challenging publicly available surveillance databases where our model outperforms the current-state-of-the-art methods. Additionally, we illustrate how the proposed architecture can be directly applied for the task of abnormal event detection without handcrafting the features.},
	urldate = {2022-05-05},
	journal = {arXiv:1702.05552 [cs]},
	author = {Fernando, Tharindu and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.05552},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Akshay\\Zotero\\storage\\GHT4C9U5\\Fernando et al. - 2017 - Soft + Hardwired Attention An LSTM Framework for .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Akshay\\Zotero\\storage\\4VB5IVPX\\1702.html:text/html},
}








